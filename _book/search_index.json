[
["index.html", "Team Programming for Scientists Preface", " Team Programming for Scientists (with examples in R) Paweł Piątkowski 2018-04-08 Preface This book is licensed under a Creative Commons Attribution-ShareAlike 4.0 International License. "],
["introduction.html", "1 Introduction", " 1 Introduction So you’ve joined a team of developers, awaiting your first programming project. Your colleague asked you to “check tickets in Jira”, “clone the repo”, and “review her PR”. In a burst of panic, your mind wanders to the safe, cozy lab you’ve just left. Would it be possible to come back…? Transitioning to professional software development may be an overwhelming, daunting experience. This short book is intended for readers (not necessarily scientists!) who have some previous programming experience, but have never worked in a development team, especially in a commercial setting. It covers basic, essential topics that you will most likely encounter during your work as a software developer. Although this book is aimed at a wide audience of programmers, regardless of the programming language they use, I decided to ground it in practice, providing examples and case studies in R and command-line Git. Why R? While it’s becoming one of the most popular languages in scientific programming, oftentimes it’s not considered a full-fledged language. R programmers (or “users”) usually lack software engineering skills, coding regime and knowledge of good programming practices, which results in poorly-written, low quality code. This book is an open source project. All pull requests are welcome (you’ll learn more about pull requests in Chapter 6 ;-)). "],
["version-control-systems-git.html", "2 Version control systems: git 2.1 Cloning a repository 2.2 Committing changes 2.3 Working on branches 2.4 Pull requests", " 2 Version control systems: git Imagine a team of architects working on a large construction design. It’s Thursday and Alice wants to work from home on Friday. She makes blueprints of the part she’s working on, makes some changes at home, and brings the blueprints to the office on Monday. Now she only needs to apply the changes she’s made to the main document, and the result is no different than as if she did the whole work at the office. Meanwhile, her colleagues can work on the other parts of the design, not bothered by Alice taking the whole documentation of out the office. The above scenario is common in software development – thanks to so called version control systems (VCS). Version control allows collaborators to: share and easily synchronize the project within the team, keep track of changes made to the documents, work simultaneously on the same project and peer-review changes. While the most popular version control system used in academia seems to be SVN (Subversion), professional software developers tend to prefer Git. Written by Linus Thorvalds (the author of Linux kernel), Git is more complex than SVN, but – arguably – gives the developer much more freedom and flexibility, with more sophisticated branching mechanism (which will be discussed in more detail further) and distributed repository architecture. Git is a free, open-source tool available for all popular platforms. To use it on your computer, you need to install it from your OS’s software repository (e.g., using apt-get on Ubuntu) or download it from the project website. Although Git is a distributed system, your team needs a place where the master copy of the repository is stored (like Alice’s office in our example.) Your company probably keeps in-house repositories on their own machine(s), but you may want to use an external hosting service for your (professional or hobby) project. Notable git hosting services include Github, Atlassian’s Bitbucket, and GitLab. The latter provides an open-source Community Edition, which can be installed on your own server and serve as a free, private hosting service. 2.1 Cloning a repository Each repository has its own URL, which can be shared with the collaborators. It looks like a typical Internet address, prefixed with either https:// (or http://), or ssh://. Cloning a repository makes a local copy on your computer – this copy itself is a complete repository, with a complete history and all branches. To clone a repository, open the command line / terminal, enter the directory where you want to keep it, and type: git clone &lt;address_of_the_repository&gt; The repository will be cloned into a subdirectory in the current path. Now you can view it, make changes to its files and create local branches, even offline, without being connected to your company’s machine. To keep your copy up-to-date, open its directory (or any subdirectory), and type: git pull This will pull changes from the origin (the remote copy of the repository) and update your working copy. Tip: Try to make a habit of updating your repository every time you start your work. 2.2 Committing changes Git keeps track of all changes made to the repository (except ignored files – they are listed in .gitignore file in the project’s directory.) When you modify a file, delete it or create a new file (or directory), it appears as a modification; you can check a list of modified files, typing: git status To view a list of changes you have made, you can view the diff. Diffs are the magic behind version control systems, since the VCS “knows” exactly what changes you have made, and only synchronizes these changes – so that the size of the repository is much smaller, and, what’s even more important, the risk of conflicts is drastically reduced. Type: git diff A detailed list of changes – line by line – is displayed. On most terminals changes are colored green (added content) and red (removed content.) If you want to commit changes made to a file (i.e., save them to your local repository), first add the file to the commit list (or stage it): git add &lt;filename.ext&gt; You can add multiple files at once, separating them by spaces, or even add all modified files: git add -A To commit the changes, type: git commit A text editor is opened (set as default for text mode; don’t be surprised if Vim or Nano is launched.1) You can type a short comment describing changes you have made. Try to be as concise and informative as possible; don’t include file names in the comment (these will be visible in the change log anyway), but rather try to describe what exactly has been done, e.g.: “Fixed a negative value bug”, or “Improved input file handling.” Your commits are automatically added to the repository change log. To view the log, type: git log When you feel that your changes can be pushed to the master repository, type: git push This will push the changes to the master branch of the repository. Usually, when working in a team, pushing to the main branch carries a significant risk of corrupting the code. Instead, you would use branches. 2.3 Working on branches In our example, Alice made blueprints of the documentation and took them home. An equivalent in version control would be branching. Like in a tree, a branch emerges from the trunk (master branch) or another branch – it’s then called a sub-branch. You can view a list of the branches in your repository, typing: git branch When you create a branch, it contains en exact copy of the “mother” branch. By default, current branch is used to create your “blueprint”: git checkout -b new_branch If you want to create a branch from another branch, you must specify its name explicitly: git checkout -b new_branch some_existing_branch You can make modifications, browse changes, and commit to your new branch just like to any other branch. You can even switch between branches – and the “snapshot” of each branch will immediately appear in your working directory. To switch to a different branch, though, your work on the current branch must be either committed or stashed. To stash changes, type: git stash Git will save the state of your current branch (both staged and unstaged files.) You can now move to another branch, work on it, and restore the stashed changes when you’re back to the previous branch: git stash apply You can even paste the stashed changes to another branch! When pushing your branch to the remote repository for the first time, you must tell Git that your local branch mirrors remote branch with the same name: git push -u origin new_branch When your work is ready to be synchronized with the main branch (like Alice did when she came to the office), you can review your changes once again, switch to the branch you want to merge your changes to (typically master), and merge them: git checkout master git pull git merge new_branch git push Now, the magic comes in: as you remember, Git keeps track only of the changes you have made, so it can painlessly merge your changes even if someone else has worked on the same project. Unless you both have made changes to the same file, that is. In our example, imagine that Alice comes to the office only to notice that Bob worked on the same part of the design. Now the changes they have made can’t be simply “put together”. This is called (unsurprisingly) a conlict. When Git detects a conflict, it doesn’t allow you to merge your changes. Instead, it creates a “superposition” of the conflicting files, with both changes made on your branch and the branch you want to merge to, separated by “fences” (&lt;&lt;&lt;&lt;&lt;&lt;&lt;, ======= and &gt;&gt;&gt;&gt;&gt;&gt;&gt;.) You need to manually resolve the conflict, removing obsolete changes (remember to remove the fences as well!), commit your work once again, and push the commit to the remote repository: git status git commit git push 2.4 Pull requests When working with hosting services like Github, you will be using one more important feature: pull requests. You make a pull request when you want to synchronize your work with the main branch – this tells your peers that you have finished your work and they can review your changes before you merge them. I will discuss the whole process further. Lifesaver for Vi/Vim: :w saves changes, :q quits the editor.↩ "],
["writing-reusable-code.html", "3 Writing reusable code 3.1 R packages 3.2 Good practices", " 3 Writing reusable code Because of its “statistical roots”, R is mostly used by statisticians and scientists - often lacking any software engineering skills. This means that the most common use case is an interactive console/RStudio session or a single-purpose script running on a fixed data set (and that’s why this chapter focuses on R, though some concepts you’ll find here are universal). That’s fine. Until you want to run your analysis for different data. Or share your code with your colleagues. Contrary to the popular belief, R is well suited to writing reusable software, or even (as you can see in other chapters) production-ready code. Its sophisticated package system, coupled with repositories like CRAN or GitHub, makes the development and distribution of programs or function libraries (packages) a breeze. 3.1 R packages R novices are intimidated by the concept of “packages” (as if it were something uncommon in programming), and creating your first package is considered as an initiation rite. Well, then, the entry threshold is really low… Although R packages can be (and sometimes are) huge and complex, with hundreds of files in lots of nested subdirectories, the minimal package is actually two files (DESCRIPTION and NAMESPACE), and a subdirectory named R/ where all your code goes. That’s it. You can create it manually in five minutes, but if you use RStudio, it’s not much more than a few clicks (File -&gt; New project... -&gt; New Directory -&gt; R package). The “bible” and basic source of information on writing R packages is Hadley Wickham’s book titled (surprisingly) R Packages. 3.2 Good practices Never ever use absolute paths (e.g., C:\\Documents\\jdoe\\R\\scripts\\myscript\\data111.csv) in your code. If you want to bundle data files with your program, put them in the inst/extdata/ subdirectory of your package and access with system.file(&quot;extdata&quot;, &quot;file.csv&quot;, package = &quot;mypackage&quot;) (note: inst is dropped when your package is built, hence the lack of it in system.file() path). It’s much better to split your code into separate .R files than to keep it all in one place. Commonly, each file comprises one exported function (a function that is “visible” outside your package and can be executed by its users) and - if needed - auxiliary functions used by the main function, and filename refers to that main function. Instead of hard-coding constants/parameters used by your functions, try to pass them as function arguments. (You can assign them default values that will be used if the user doesn’t explicitly choose otherwise.) "],
["unit-tests.html", "4 Unit tests 4.1 An ideal unit test 4.2 Test conditions 4.3 Test-Driven Development 4.4 Unit testing in R", " 4 Unit tests Unit tests are like seat belts: they seem to be only complicating your life – until an accident happens. Imagine you’re writing a function that takes an input and returns some result. Unless your function performs trivial calculations, like a single mathematical operation, you need to check somehow if it’s well written. Typically, you would execute your function with several sets of input parameters and verify if the output is correct. Now imagine that you have dozens of functions in your project, some of them very sophisticated, and you decide to optimize the workflow. Or completely change the architecture of your program. What would you do? What comes to mind, is: try to automate it, writing a script that would execute your functions with a predefined set of input parameters each time it’s launched. Now add automatic output validation and you get unit tests. In a team setting, unit tests are important for one more reason: they can tell your peers or future developers what exactly you expect your function to do. Sometimes documentation is not enough when your function deals with complicated input. Unit testing routines are available for most programming languages – usually as separate libraries. Basic procedure almost always looks roughly the same: a single test case consists of the execution of one function and the expected output. 4.1 An ideal unit test Ideally, unit tests should follow these rules: They should reflect the goal of the function – one should be able to infer what the function does by reading the test… …but they can’t duplicate the logic of the function – if you share function’s code with the test, you may be sharing bugs as well. They must not be changed after refactoring the function – this would undermine the point of unit testing. They shouldn’t be redundant – a test for one unit of code should be written and executed only once. They should cover the smallest possible portion of code (hence the name), usually one function – you shouldn’t confuse unit tests with integration tests, which check the cooperation of elements within the program. It’s hard to follow these rules to a T – sometimes the structure of your application makes it hard to split into easily testable functions, or these functions are so interdependent that they can’t be tested separately – but the more closely you’ll follow them, the more you’ll get from your tests. 4.2 Test conditions One of the most important tasks when writing unit test is the proper design of testing conditions. Let’s consider a trivial example: divide = function(x, y) { x / y } Now, you can test this functions for some made-up values of x and y [examples written using testthat package for R]: expect_equal(divide(1, 2), 0.5) expect_equal(divide(10, 5), 2) # etc... but it makes little sense. Instead, you should think about some tricky cases: divide(1, 0) # should it return Inf or throw an error? divide(1e300, 1e300) # what about large numbers? divide(5, &quot;10&quot;) # what if one of the arguments is not numeric? From this simple case you can see that designing test conditions makes you think about the intended behavior of your function and, sometimes, about the goal of writing it. Which leads us to the next point… 4.3 Test-Driven Development Test-driven development (abbreviated TDD) is a step forward in writing unit tests. Instead of writing tests for the existing code, you write them… before the tested functions are even created. What’s the point of this? How is it even possible? When you write a unit test for a non-existent function, you have to thoroughly think over its input and desired output (as we saw in the previous section), what the function should actually do and how it would interact with other parts of the program. Obviously the test will initially fail, because there’s no function yet, but when you eventually write it, it should behave exactly as intended by the test – and that’s the point of TDD: the program is ready when all tests pass. I’m not advocating TDD – I hardly ever use it – but I strongly recommend following the philosophy of TDD: design your tests so that when a test fails, you refactor the tested function, not the test. 4.4 Unit testing in R There are several packages for unit testing in R, RUnit and testthat being the most widely used. While the latter seems to be more popular and actively maintained, both are perfectly valid for writing unit tests and the choice of one over the other is up to your preference (or the guidelines for the project). "]
]
